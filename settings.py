LEARNING_RATE = 0.0003
N_EPOCH = 200
BATCH_SIZE = 100
GRU_LAMBDA = (0.0, 0.003,)
DENSE_LAMBDA = (0.0, 0.003, 0.01,)
VOCABULARY_SIZE = 70000
TITLE_LEN = 50
CONTENT_LEN = 500
TITLE_OUTPUT = 512
CONTENT_OUTPUT = 768
DENSE_NEURONS = (1024,)
DATASET = 'reuters'
